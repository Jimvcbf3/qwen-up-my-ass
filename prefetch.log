[prefetch] processor Qwen/Qwen2-VL-7B-Instruct

---STDERR---
D:\QWEN2-VL7B project\.venv\lib\site-packages\transformers\utils\hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
D:\QWEN2-VL7B project\.venv\lib\site-packages\huggingface_hub\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\QWEN2-VL7B project\hf_cache\models--Qwen--Qwen2-VL-7B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]Fetching 1 files: 100%|##########| 1/1 [00:00<?, ?it/s]
Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]Fetching 1 files: 100%|##########| 1/1 [00:00<?, ?it/s]
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Traceback (most recent call last):
  File "D:\QWEN2-VL7B project\prefetch_qwen.py", line 4, in <module>
    AutoProcessor.from_pretrained(m, trust_remote_code=True)
  File "D:\QWEN2-VL7B project\.venv\lib\site-packages\transformers\models\auto\processing_auto.py", line 391, in from_pretrained
    return processor_class.from_pretrained(
  File "D:\QWEN2-VL7B project\.venv\lib\site-packages\transformers\processing_utils.py", line 1331, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "D:\QWEN2-VL7B project\.venv\lib\site-packages\transformers\processing_utils.py", line 1390, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "D:\QWEN2-VL7B project\.venv\lib\site-packages\transformers\utils\import_utils.py", line 2142, in __getattribute__
    requires_backends(cls, cls._backends)
  File "D:\QWEN2-VL7B project\.venv\lib\site-packages\transformers\utils\import_utils.py", line 2128, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
AutoVideoProcessor requires the Torchvision library but it was not found in your environment. Check out the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.


